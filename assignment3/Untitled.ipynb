{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas \n",
    "from numpy.linalg import inv\n",
    "import random\n",
    "import csv\n",
    "import math\n",
    "import sklearn\n",
    "from sklearn.svm import LinearSVC\n",
    "from collections import Counter\n",
    "import string\n",
    "import operator\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse import vstack\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "import scipy.sparse as sps\n",
    "from sklearn import tree\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import f1_score \n",
    "from sklearn.dummy import DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "yelp_train_x = []\n",
    "yelp_train_y = []\n",
    "yelp_valid_x = []\n",
    "yelp_valid_y = []\n",
    "yelp_test_x = []\n",
    "yelp_test_y = []\n",
    "\n",
    "translation = str.maketrans(\"\", \"\", string.punctuation)\n",
    "\n",
    "\n",
    "with open('./yelp-train.txt') as f:\n",
    "    for line in f:\n",
    "        yelp_train_x.append(line[:-3].translate(translation).lower())\n",
    "        yelp_train_y.append(int(line[-2]))\n",
    "        \n",
    "with open('./yelp-valid.txt') as f:\n",
    "    for line in f:\n",
    "        yelp_valid_x.append(line[:-3].translate(translation).lower())\n",
    "        yelp_valid_y.append(int(line[-2]))\n",
    "        \n",
    "with open('./yelp-test.txt') as f:\n",
    "    for line in f:\n",
    "        yelp_test_x.append(line[:-3].translate(translation).lower())\n",
    "        yelp_test_y.append(int(line[-2]))\n",
    "        \n",
    "wordfreq = {}\n",
    "\n",
    "for row in yelp_train_x:\n",
    "    words = row.split(\" \")\n",
    "    j = 0\n",
    "    for word in words:\n",
    "        if word == ' ' or word == '':\n",
    "            continue\n",
    "        if word not in wordfreq:\n",
    "            wordfreq[word] = (j,1)\n",
    "        else:\n",
    "            wordfreq[word] = (j, wordfreq[word][1]+ 1)\n",
    "        j += 1\n",
    "    \n",
    "    \n",
    "\n",
    "sorted_wordfreq = sorted(wordfreq.items(), key=lambda x:x[1][1], reverse = True)[:10000]  \n",
    "sorted_wordfreq_dict = dict(sorted_wordfreq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def bag_of_words_represntation(data, sorted_wordfreq_dict):\n",
    "    DM_binary = []\n",
    "    DM_frequency = []\n",
    "    for x in data:\n",
    "        vector_binary = np.zeros(len(sorted_wordfreq_dict))\n",
    "        vector_frequency = np.zeros(len(sorted_wordfreq_dict))\n",
    "        for y in x.split(' '):\n",
    "            if y in sorted_wordfreq_dict:\n",
    "                index = sorted_wordfreq_dict[y][0]\n",
    "                if (vector_binary[index] == 0):\n",
    "                    vector_binary[index] = 1\n",
    "                vector_frequency[index] += 1                \n",
    "        DM_binary.append(vector_binary)\n",
    "        if (sum(vector_frequency) != 0):\n",
    "            vector_frequency = vector_frequency/sum(vector_frequency)\n",
    "        \n",
    "        DM_frequency.append(vector_frequency)   \n",
    "    return DM_frequency, DM_binary\n",
    "\n",
    "train_frequency_design, train_binary_design = bag_of_words_represntation(yelp_train_x, sorted_wordfreq_dict)\n",
    "valid_frequency_design, valid_binary_design = bag_of_words_represntation(yelp_valid_x, sorted_wordfreq_dict)\n",
    "test_frequency_design, test_binary_design = bag_of_words_represntation(yelp_test_x, sorted_wordfreq_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "yelp_vocab = []\n",
    "for i in range(0,len(sorted_wordfreq)):\n",
    "    yelp_vocab.append(' '.join([str(sorted_wordfreq[i][0]),'\\t',str(i+1) , '\\t', str(sorted_wordfreq[i][1][1])]))\n",
    "yelp_train = []\n",
    "for i in range(0,len(yelp_train_x)):\n",
    "    toadd = []\n",
    "    for j in yelp_train_x[i].split(' '):\n",
    "        if j in sorted_wordfreq_dict:\n",
    "            toadd.append(str(sorted_wordfreq_dict[j][0]))\n",
    "    toadd.append('\\t')\n",
    "    toadd.append(str(yelp_train_y[i]))\n",
    "    toadd = ' '.join(toadd)\n",
    "    yelp_train.append(toadd)        \n",
    "yelp_valid = []\n",
    "for i in range(0,len(yelp_valid_x)):\n",
    "    toadd = []\n",
    "    for j in yelp_valid_x[i].split(' '):\n",
    "        if j in sorted_wordfreq_dict:\n",
    "            toadd.append(str(sorted_wordfreq_dict[j][0]))\n",
    "    toadd.append('\\t')            \n",
    "    toadd.append(str(yelp_valid_y[i]))\n",
    "    toadd = ' '.join(toadd)    \n",
    "    yelp_valid.append(toadd)\n",
    "yelp_test = []\n",
    "for i in range(0,len(yelp_test_x)):\n",
    "    toadd = []\n",
    "    for j in yelp_test_x[i].split(' '):\n",
    "        if j in sorted_wordfreq_dict:\n",
    "            toadd.append(str(sorted_wordfreq_dict[j][0]))\n",
    "    toadd.append('\\t')\n",
    "    toadd.append(str(yelp_test_y[i]))\n",
    "    toadd =' '.join(toadd)    \n",
    "    yelp_test.append(toadd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"./data/yelp-vocab.txt\", \"w\")\n",
    "for i in yelp_vocab:\n",
    "    file.write(i)\n",
    "    file.write('\\n')\n",
    "file = open(\"./data/yelp-train.txt\", \"w\")\n",
    "for i in yelp_train:\n",
    "    file.write(i)\n",
    "    file.write('\\n')    \n",
    "file = open(\"./data/yelp-valid.txt\", \"w\")\n",
    "for i in yelp_valid:\n",
    "    file.write(i)\n",
    "    file.write('\\n')    \n",
    "file = open(\"./data/yelp-test.txt\", \"w\")\n",
    "for i in yelp_test:\n",
    "    file.write(i)\n",
    "    file.write('\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The f1_measure on training set for bernoulli naive bayes using binary bag of words is :0.40214285714285714\n",
      "The f1_measure on validation set for bernoulli naive bayes using binary bag of words is :0.357\n",
      "The f1_measure on test set for bernoulli naive bayes using binary bag of words is :0.3835\n",
      "Corresponding alpha is 1e-90\n",
      "The f1_measure on training set for classification tree using binary bag of words is :1.0\n",
      "The f1_measure on validation set for classification tree using binary bag of words is :0.336\n",
      "The f1_measure on test set for classification tree using binary bag of words is :0.325\n",
      "Corresponding max_features, min_samples_leaf, max_depth are 1, 1, 1\n",
      "The f1_measure on trainig set for LinearSVC using binary bag of words is :0.6052857142857143\n",
      "The f1_measure on validation set for LinearSVC using binary bag of words is :0.418\n",
      "The f1_measure on test set for LinearSVC using binary bag of words is :0.429\n",
      "The corresponding vlaue of C is 1e-90\n",
      "The f1_measure on test set for Random classifier is :0.21499999999999997\n",
      "The f1_measure on test set for majority-class classifier is :0.351\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "########hyper parameter tuning######\n",
    "\n",
    "##BernoulliNB alpha tuning##\n",
    "\n",
    "clf = BernoulliNB()\n",
    "clf.fit(train_binary_design, yelp_train_y)\n",
    "\n",
    "\n",
    "parameters = []\n",
    "for i in range(0,100):\n",
    "    parameters.append(math.pow(10,(i-90)))\n",
    "best_f1 = -10\n",
    "k = 0\n",
    "for i in parameters:\n",
    "    clf.alpha = i\n",
    "    f1_measure = f1_score(yelp_valid_y,clf.predict(valid_binary_design), average='micro')\n",
    "    if (best_f1 < f1_measure):\n",
    "        k = i\n",
    "        best_f1 = f1_measure\n",
    "clf.alpha = k   \n",
    "print(\"The f1_measure on training set for bernoulli naive bayes using binary bag of words is :\" +\n",
    "      str(f1_score(y_true = yelp_train_y, y_pred = clf.predict(train_binary_design), average = 'micro')))\n",
    "print(\"The f1_measure on validation set for bernoulli naive bayes using binary bag of words is :\" + \n",
    "      str(f1_score(y_true = yelp_valid_y, y_pred = clf.predict(valid_binary_design), average = 'micro')))\n",
    "\n",
    "print(\"The f1_measure on test set for bernoulli naive bayes using binary bag of words is :\" + str(f1_score(y_true = yelp_test_y, y_pred = clf.predict(test_binary_design), average = 'micro')))\n",
    "print(\"Corresponding alpha is \" + str(clf.alpha))\n",
    "\n",
    "####Decision tree max leaf, min sample max depth training\n",
    "\n",
    "\n",
    "\n",
    "decision_tree = tree.DecisionTreeClassifier()\n",
    "decision_tree.fit(train_binary_design, yelp_train_y)\n",
    "\n",
    "\n",
    "max_features = [i for i in range(1,20)]\n",
    "min_samples_leaf = [i for i in range(1,20)]\n",
    "max_depth = [i for i in range(1,20)]\n",
    "best_f1_2 = -10\n",
    "best_i = 0\n",
    "best_j = 0\n",
    "best_k = 0 \n",
    "for i in max_features:\n",
    "    for j in min_samples_leaf:\n",
    "        for k in max_depth:\n",
    "            decision_tree.max_features = i\n",
    "            decision_tree.min_samples_leaf = j\n",
    "            decision_tree.max_depth = k\n",
    "            f1_measure = f1_score(yelp_valid_y,decision_tree.predict(valid_binary_design), average='micro')\n",
    "            if (best_f1_2 < f1_measure):\n",
    "                best_i = i\n",
    "                best_j = j\n",
    "                best_k = k \n",
    "                best_f1_2 = f1_measure\n",
    "decision_tree.max_features = best_i\n",
    "decision_tree.min_samples_leaf = best_j\n",
    "decision_tree.max_depth = best_k\n",
    "print(\"The f1_measure on training set for classification tree using binary bag of words is :\" \n",
    "      + str(f1_score(y_true = yelp_train_y, y_pred = decision_tree.predict(train_binary_design), average = 'micro')))\n",
    "print(\"The f1_measure on validation set for classification tree using binary bag of words is :\" \n",
    "      + str(f1_score(y_true = yelp_valid_y, y_pred = decision_tree.predict(valid_binary_design), average = 'micro')))\n",
    "\n",
    "\n",
    "print(\"The f1_measure on test set for classification tree using binary bag of words is :\" + str(f1_score(y_true = yelp_test_y, y_pred = decision_tree.predict(test_binary_design), average = 'micro')))\n",
    "print(\"Corresponding max_features, min_samples_leaf, max_depth are \" + str(best_i) +\n",
    "      \", \" + str(best_j)+ \", \" +str(best_k))\n",
    "\n",
    "####Decision tree max leaf, min sample max depth training \n",
    "      \n",
    "lin_clf = LinearSVC()\n",
    "lin_clf.fit(train_binary_design, yelp_train_y)\n",
    "\n",
    "\n",
    "C = []\n",
    "for i in range(0,100):\n",
    "    C.append(math.pow(10,(i-90)))\n",
    "\n",
    "best_f1_3 = -10\n",
    "k=0\n",
    "for i in C:\n",
    "    lin_clf.C = i\n",
    "    f1_measure = f1_score(yelp_valid_y,lin_clf.predict(valid_binary_design), average='micro')\n",
    "    if (best_f1_3 < f1_measure):\n",
    "        k = i\n",
    "        best_f1_3 = f1_measure\n",
    "lin_clf.C = k    \n",
    "\n",
    "\n",
    "print(\"The f1_measure on trainig set for LinearSVC using binary bag of words is :\" + str(f1_score(yelp_train_y, lin_clf.predict(train_binary_design), average = 'micro')))\n",
    "print(\"The f1_measure on validation set for LinearSVC using binary bag of words is :\" + str(f1_score(yelp_valid_y, lin_clf.predict(valid_binary_design), average = 'micro')))\n",
    "print(\"The f1_measure on test set for LinearSVC using binary bag of words is :\" + str(f1_score(yelp_test_y, lin_clf.predict(test_binary_design), average = 'micro')))\n",
    "\n",
    "print(\"The corresponding vlaue of C is \" + str(lin_clf.C))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "uniform_classifier = DummyClassifier(strategy='uniform')\n",
    "uniform_classifier.fit(train_binary_design, yelp_train_y)\n",
    "print(\"The f1_measure on test set for Random classifier is :\" + str(f1_score(yelp_test_y,uniform_classifier.predict(test_binary_design), average = 'micro')))\n",
    "\n",
    "\n",
    "majority_classifier = DummyClassifier(strategy='most_frequent') \n",
    "majority_classifier.fit(train_binary_design, yelp_train_y)\n",
    "\n",
    "print(\"The f1_measure on test set for majority-class classifier is :\" + str(f1_score(yelp_test_y, majority_classifier.predict(test_binary_design), average = 'micro')))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The f1_measure on train set for bernoulli naive bayes using frequency bag of words is :0.22557142857142856\n",
      "The f1_measure on validation set for bernoulli naive bayes using frequency bag of words is :0.141\n",
      "The f1_measure on test set for bernoulli naive bayes using frequency bag of words is :0.16\n",
      "Corresponding alpha is 1e-90\n",
      "The f1_measure on training set for classification tree using frequency bag of words is :1.0\n",
      "The f1_measure on validation set for classification tree using frequency bag of words is :0.294\n",
      "The f1_measure on test set for classification tree using frequency bag of words is :0.323\n",
      "Corresponding max_features, min_samples_leaf, max_depth are 1, 1, 1\n",
      "The f1_measure on training set for LinearSVC using frequency bag of words is :0.4714285714285714\n",
      "The f1_measure on validation set for LinearSVC using frequency bag of words is :0.42299999999999993\n",
      "The f1_measure on testing set for LinearSVC using frequency bag of words is :0.4415\n",
      "The corresponding vlaue of C is 1e-90\n",
      "The f1_measure on test set for Random classifier is :0.1975\n",
      "The f1_measure on test set for majority-class classifier is : 0.351\n"
     ]
    }
   ],
   "source": [
    " \n",
    "\n",
    "########hyper parameter tuning######\n",
    "\n",
    "##BernoulliNB alpha tuning##\n",
    "\n",
    "clf = GaussianNB()\n",
    "clf.fit(train_frequency_design, yelp_train_y)\n",
    "\n",
    "\n",
    "parameters = []\n",
    "for i in range(0,100):\n",
    "    parameters.append(math.pow(10,(i-90)))\n",
    "best_f1 = -10\n",
    "k = 0\n",
    "for i in parameters:\n",
    "    clf.alpha = i\n",
    "    f1_measure = f1_score(yelp_valid_y,clf.predict(valid_frequency_design), average='micro')\n",
    "    if (best_f1 < f1_measure):\n",
    "        k = i\n",
    "        best_f1 = f1_measure\n",
    "clf.alpha = k   \n",
    "\n",
    "print(\"The f1_measure on train set for Gaussian naive bayes using frequency bag of words is :\"\n",
    "      + str(f1_score(y_true = yelp_train_y, y_pred = clf.predict(train_frequency_design), average = 'micro')))\n",
    "print(\"The f1_measure on validation set for Gaussian naive bayes using frequency bag of words is :\"\n",
    "      + str(f1_score(y_true = yelp_valid_y, y_pred = clf.predict(valid_frequency_design), average = 'micro')))\n",
    "\n",
    "\n",
    "print(\"The f1_measure on test set for Gaussian naive bayes using frequency bag of words is :\"\n",
    "      + str(f1_score(y_true = yelp_test_y, y_pred = clf.predict(test_frequency_design), average = 'micro')))\n",
    "print(\"Corresponding alpha is \" + str(clf.alpha))\n",
    "\n",
    "\n",
    "####Decision tree max leaf, min sample max depth training\n",
    "\n",
    "\n",
    "\n",
    "decision_tree = tree.DecisionTreeClassifier()\n",
    "decision_tree.fit(train_frequency_design, yelp_train_y)\n",
    "\n",
    "\n",
    "max_features = [i for i in range(1,20)]\n",
    "min_samples_leaf = [i for i in range(1,20)]\n",
    "max_depth = [i for i in range(1,20)]\n",
    "best_f1_2 = -10\n",
    "best_i = 0\n",
    "best_j = 0\n",
    "best_k = 0 \n",
    "for i in max_features:\n",
    "    for j in min_samples_leaf:\n",
    "        for k in max_depth:\n",
    "            decision_tree.max_features = i\n",
    "            decision_tree.min_samples_leaf = j\n",
    "            decision_tree.max_depth = k\n",
    "            f1_measure = f1_score(yelp_valid_y,decision_tree.predict(valid_frequency_design), average='micro')\n",
    "            if (best_f1_2 < f1_measure):\n",
    "                best_i = i\n",
    "                best_j = j\n",
    "                best_k = k \n",
    "                best_f1_2 = f1_measure\n",
    "decision_tree.max_features = best_i\n",
    "decision_tree.max_features = best_j\n",
    "decision_tree.max_features = best_k \n",
    "print(\"The f1_measure on training set for classification tree using frequency bag of words is :\"\n",
    "      + str(f1_score(y_true = yelp_train_y, y_pred = decision_tree.predict(train_frequency_design), average = 'micro')))\n",
    "\n",
    "print(\"The f1_measure on validation set for classification tree using frequency bag of words is :\"\n",
    "      + str(f1_score(y_true = yelp_valid_y, y_pred = decision_tree.predict(valid_frequency_design), average = 'micro')))\n",
    "\n",
    "print(\"The f1_measure on test set for classification tree using frequency bag of words is :\"\n",
    "      + str(f1_score(y_true = yelp_test_y, y_pred = decision_tree.predict(test_frequency_design), average = 'micro')))\n",
    "print(\"Corresponding max_features, min_samples_leaf, max_depth are \" \n",
    "      + str(best_i) + \", \" + str(best_j)+ \", \" +str(best_k))\n",
    "\n",
    "\n",
    "####Decision tree max leaf, min sample max depth training \n",
    "\n",
    "lin_clf = LinearSVC()\n",
    "lin_clf.fit(train_frequency_design, yelp_train_y)\n",
    "\n",
    "\n",
    "C = []\n",
    "for i in range(0,100):\n",
    "    C.append(math.pow(10,(i-90)))\n",
    "\n",
    "best_f1_3 = -10\n",
    "k=0\n",
    "for i in C:\n",
    "    lin_clf.C = i\n",
    "    f1_measure = f1_score(yelp_valid_y,lin_clf.predict(valid_frequency_design), average='micro')\n",
    "    if (best_f1_3 < f1_measure):\n",
    "        k = i\n",
    "        best_f1_3 = f1_measure\n",
    "lin_clf.C = k    \n",
    "\n",
    "\n",
    "\n",
    "print(\"The f1_measure on training set for LinearSVC using frequency bag of words is :\"\n",
    "      + str(f1_score(yelp_train_y, lin_clf.predict(train_frequency_design), average = 'micro')))\n",
    "\n",
    "print(\"The f1_measure on validation set for LinearSVC using frequency bag of words is :\"\n",
    "      + str(f1_score(yelp_valid_y, lin_clf.predict(valid_frequency_design), average = 'micro')))\n",
    "\n",
    "print(\"The f1_measure on testing set for LinearSVC using frequency bag of words is :\"\n",
    "      + str(f1_score(yelp_test_y, lin_clf.predict(test_frequency_design), average = 'micro')))\n",
    "\n",
    "\n",
    "print(\"The corresponding vlaue of C is \" + str(lin_clf.C))\n",
    "\n",
    "\n",
    "\n",
    "uniform_classifier = DummyClassifier(strategy='uniform')\n",
    "uniform_classifier.fit(train_binary_design, yelp_train_y)\n",
    "print(\"The f1_measure on test set for Random classifier is :\" \n",
    "      + str(f1_score(yelp_test_y,uniform_classifier.predict(test_frequency_design), average = 'micro')))\n",
    "\n",
    "\n",
    "majority_classifier = DummyClassifier(strategy='most_frequent') \n",
    "majority_classifier.fit(train_frequency_design, yelp_train_y)\n",
    "\n",
    "print(\"The f1_measure on test set for majority-class classifier is : \" + \n",
    "      str(f1_score(yelp_test_y, majority_classifier.predict(test_frequency_design), average = 'micro')))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMDB_train_x = []\n",
    "IMDB_train_y = []\n",
    "IMDB_valid_x = []\n",
    "IMDB_valid_y = []\n",
    "IMDB_test_x = []\n",
    "IMDB_test_y = []\n",
    "\n",
    "translation = str.maketrans(\"\", \"\", string.punctuation)\n",
    "\n",
    "\n",
    "with open('./IMDB-train.txt') as f:\n",
    "    for line in f:\n",
    "        IMDB_train_x.append(line[:-3].translate(translation).lower())\n",
    "        IMDB_train_y.append(int(line[-2]))\n",
    "        \n",
    "with open('./IMDB-valid.txt') as f:\n",
    "    for line in f:\n",
    "        IMDB_valid_x.append(line[:-3].translate(translation).lower())\n",
    "        IMDB_valid_y.append(int(line[-2]))\n",
    "        \n",
    "with open('./IMDB-test.txt') as f:\n",
    "    for line in f:\n",
    "        IMDB_test_x.append(line[:-3].translate(translation).lower())\n",
    "        IMDB_test_y.append(int(line[-2]))\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "wordfreq = {}\n",
    "for row in IMDB_train_x:\n",
    "    words = row.split(\" \")\n",
    "    j = 0\n",
    "    for word in words:\n",
    "        if word == ' ' or word == '':\n",
    "            continue\n",
    "        if word not in wordfreq:\n",
    "            wordfreq[word] = (j,1)\n",
    "        else:\n",
    "            wordfreq[word] = (j, wordfreq[word][1]+ 1)\n",
    "        j += 1\n",
    "\n",
    "sorted_wordfreq = sorted(wordfreq.items(), key=lambda x:x[1][1], reverse = True)[:10000]  \n",
    "sorted_wordfreq_dict = dict(sorted_wordfreq)\n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def bag_of_words_represntation(data, sorted_wordfreq_dict):\n",
    "    DM_binary = []\n",
    "    DM_frequency = []\n",
    "    for x in data:\n",
    "        vector_binary = np.zeros(len(sorted_wordfreq_dict))\n",
    "        vector_frequency = np.zeros(len(sorted_wordfreq_dict))\n",
    "        for y in x.split(' '):\n",
    "            if y in sorted_wordfreq_dict:\n",
    "                index = sorted_wordfreq_dict[y][0]\n",
    "                if (vector_binary[index] == 0):\n",
    "                    vector_binary[index] = 1\n",
    "                vector_frequency[index] += 1                \n",
    "        DM_binary.append(vector_binary)\n",
    "        if (sum(vector_frequency) != 0):\n",
    "            vector_frequency = vector_frequency/sum(vector_frequency)\n",
    "        DM_frequency.append(vector_frequency)\n",
    "            \n",
    "    return csr_matrix(DM_frequency), csr_matrix(DM_binary)\n",
    "\n",
    "train_frequency_design, train_binary_design = bag_of_words_represntation(IMDB_train_x, sorted_wordfreq_dict)\n",
    "valid_frequency_design, valid_binary_design = bag_of_words_represntation(IMDB_valid_x, sorted_wordfreq_dict)\n",
    "test_frequency_design, test_binary_design = bag_of_words_represntation(IMDB_test_x, sorted_wordfreq_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMDB_vocab = []\n",
    "for i in range(0,len(sorted_wordfreq)):\n",
    "    IMDB_vocab.append(' '.join([str(sorted_wordfreq[i][0]),'\\t',str(i+1) , '\\t', str(sorted_wordfreq[i][1][1])]))\n",
    "IMDB_train = []\n",
    "for i in range(0,len(IMDB_train_x)):\n",
    "    toadd = []\n",
    "    for j in IMDB_train_x[i].split(' '):\n",
    "        if j in sorted_wordfreq_dict:\n",
    "            toadd.append(str(sorted_wordfreq_dict[j][0]))\n",
    "    toadd.append('\\t')\n",
    "    toadd.append(str(IMDB_train_y[i]))\n",
    "    toadd = ' '.join(toadd)    \n",
    "    IMDB_train.append(toadd)        \n",
    "IMDB_valid = []\n",
    "for i in range(0,len(IMDB_valid_x)):\n",
    "    toadd = []\n",
    "    for j in IMDB_valid_x[i].split(' '):\n",
    "        if j in sorted_wordfreq_dict:\n",
    "            toadd.append(str(sorted_wordfreq_dict[j][0]))\n",
    "    toadd.append('\\t')            \n",
    "    toadd.append(str(IMDB_valid_y[i]))\n",
    "    toadd = ' '.join(toadd)    \n",
    "    IMDB_valid.append(toadd)\n",
    "IMDB_test = []\n",
    "for i in range(0,len(IMDB_test_x)):\n",
    "    toadd = []\n",
    "    for j in IMDB_test_x[i].split(' '):\n",
    "        if j in sorted_wordfreq_dict:\n",
    "            toadd.append(str(sorted_wordfreq_dict[j][0]))\n",
    "    toadd.append('\\t')\n",
    "    toadd.append(str(IMDB_test_y[i]))\n",
    "    toadd = ' '.join(toadd)\n",
    "    \n",
    "    IMDB_test.append(toadd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"./data/IMDB-vocab.txt\", \"w\")\n",
    "for i in IMDB_vocab:\n",
    "    file.write(i)\n",
    "    file.write('\\n')    \n",
    "file = open(\"./data/IMDB-train.txt\", \"w\")\n",
    "for i in IMDB_train:\n",
    "    file.write(i)\n",
    "    file.write('\\n')    \n",
    "file = open(\"./data/IMDB-valid.txt\", \"w\")\n",
    "for i in IMDB_valid:\n",
    "    file.write(i)\n",
    "    file.write('\\n')    \n",
    "file = open(\"./data/IMDB-test.txt\", \"w\")\n",
    "for i in IMDB_test:\n",
    "    file.write(i)\n",
    "    file.write('\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21 9 45 1 53 348 83 152 126 266 9 155 58 112 123 118 21 44 134 118 9 45 72 448 38 157 36 52 38 9 207 41 85 38 120 123 324 273 21 61 41 239 25 347 9 127 387 \t 1\n"
     ]
    }
   ],
   "source": [
    "print(IMDB_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The f1_measure on training set for bernoulli naive bayes using binary bag of words is :0.7748666666666667\n",
      "The f1_measure on valid set for bernoulli naive bayes using binary bag of words is :0.7596\n",
      "The f1_measure on test set for bernoulli naive bayes using binary bag of words is :0.7571200000000001\n",
      "Corresponding alpha is 1e-90\n",
      "The f1_measure on training set for classification tree using binary bag of words is :1.0\n",
      "The f1_measure on validation set for classification tree using binary bag of words is :0.6041\n",
      "The f1_measure on test set for classification tree using binary bag of words is :0.6094\n",
      "Corresponding max_features, min_samples_leaf, max_depth are 1, 1, 1\n",
      "The f1_measure on training set for LinearSVC using binary bag of words is :0.8140000000000001\n",
      "The f1_measure on validation set for LinearSVC using binary bag of words is :0.7717\n",
      "The f1_measure on test set for LinearSVC using binary bag of words is :0.77124\n",
      "The corresponding vlaue of C is 1e-90\n",
      "The f1_measure on test set for Random classifier is :0.5004\n",
      "The f1_measure on test set for majority-class classifier is :0.5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "########hyper parameter tuning######\n",
    "\n",
    "##BernoulliNB alpha tuning##\n",
    "\n",
    "clf = BernoulliNB()\n",
    "clf.fit(train_binary_design, IMDB_train_y)\n",
    "\n",
    "\n",
    "parameters = []\n",
    "for i in range(0,100):\n",
    "    parameters.append(math.pow(10,(i-90)))\n",
    "best_f1 = -10\n",
    "k = 0\n",
    "for i in parameters:\n",
    "    clf.alpha = i\n",
    "    f1_measure = f1_score(IMDB_valid_y,clf.predict(valid_binary_design), average='micro')\n",
    "    if (best_f1 < f1_measure):\n",
    "        k = i\n",
    "        best_f1 = f1_measure\n",
    "clf.alpha = k   \n",
    "\n",
    "print(\"The f1_measure on training set for bernoulli naive bayes using binary bag of words is :\" \n",
    "      + str(f1_score(y_true =IMDB_train_y, y_pred = clf.predict(train_binary_design), average = 'micro')))\n",
    "print(\"The f1_measure on valid set for bernoulli naive bayes using binary bag of words is :\" \n",
    "      + str(f1_score(y_true =IMDB_valid_y, y_pred = clf.predict(valid_binary_design), average = 'micro')))\n",
    "print(\"The f1_measure on test set for bernoulli naive bayes using binary bag of words is :\" \n",
    "      + str(f1_score(y_true =IMDB_test_y, y_pred = clf.predict(test_binary_design), average = 'micro')))\n",
    "print(\"Corresponding alpha is \" + str(clf.alpha))\n",
    "\n",
    "\n",
    "####Decision tree max leaf, min sample max depth training\n",
    "\n",
    "\n",
    "\n",
    "decision_tree = tree.DecisionTreeClassifier()\n",
    "decision_tree.fit(train_binary_design, IMDB_train_y)\n",
    "\n",
    "\n",
    "max_features = [i for i in range(1,20)]\n",
    "min_samples_leaf = [i for i in range(1,20)]\n",
    "max_depth = [i for i in range(1,20)]\n",
    "best_f1_2 = -10\n",
    "best_i = 0\n",
    "best_j = 0\n",
    "best_k = 0 \n",
    "for i in max_features:\n",
    "    for j in min_samples_leaf:\n",
    "        for k in max_depth:\n",
    "            decision_tree.max_features = i\n",
    "            decision_tree.min_samples_leaf = j\n",
    "            decision_tree.max_depth = k\n",
    "            f1_measure = f1_score(IMDB_valid_y,decision_tree.predict(valid_binary_design), average='micro')\n",
    "            if (best_f1_2 < f1_measure):\n",
    "                best_i = i\n",
    "                best_j = j\n",
    "                best_k = k \n",
    "                best_f1_2 = f1_measure\n",
    "decision_tree.max_features = best_i\n",
    "decision_tree.max_features = best_j\n",
    "decision_tree.max_features = best_k \n",
    "print(\"The f1_measure on training set for classification tree using binary bag of words is :\" \n",
    "      + str(f1_score(y_true = IMDB_train_y, y_pred = decision_tree.predict(train_binary_design), average = 'micro')))\n",
    "print(\"The f1_measure on validation set for classification tree using binary bag of words is :\" \n",
    "      + str(f1_score(y_true = IMDB_valid_y, y_pred = decision_tree.predict(valid_binary_design), average = 'micro')))\n",
    "print(\"The f1_measure on test set for classification tree using binary bag of words is :\" \n",
    "      + str(f1_score(y_true = IMDB_test_y, y_pred = decision_tree.predict(test_binary_design), average = 'micro')))\n",
    "print(\"Corresponding max_features, min_samples_leaf, max_depth are \" \n",
    "      + str(best_i) + \", \" + str(best_j)+ \", \" +str(best_k))\n",
    "\n",
    "\n",
    "####Decision tree max leaf, min sample max depth training \n",
    "\n",
    "lin_clf = LinearSVC()\n",
    "lin_clf.fit(train_binary_design, IMDB_train_y)\n",
    "\n",
    "\n",
    "C = []\n",
    "for i in range(0,100):\n",
    "    C.append(math.pow(10,(i-90)))\n",
    "\n",
    "best_f1_3 = -10\n",
    "k=0\n",
    "for i in C:\n",
    "    lin_clf.C = i\n",
    "    f1_measure = f1_score(IMDB_valid_y,lin_clf.predict(valid_binary_design), average='micro')\n",
    "    if (best_f1_3 < f1_measure):\n",
    "        k = i\n",
    "        best_f1_3 = f1_measure\n",
    "lin_clf.C = k    \n",
    "print(\"The f1_measure on training set for LinearSVC using binary bag of words is :\" \n",
    "      + str(f1_score(IMDB_train_y, lin_clf.predict(train_binary_design), average = 'micro')))\n",
    "print(\"The f1_measure on validation set for LinearSVC using binary bag of words is :\" \n",
    "      + str(f1_score(IMDB_valid_y, lin_clf.predict(valid_binary_design), average = 'micro')))\n",
    "print(\"The f1_measure on test set for LinearSVC using binary bag of words is :\" \n",
    "      + str(f1_score(IMDB_test_y, lin_clf.predict(test_binary_design), average = 'micro')))\n",
    "print(\"The corresponding vlaue of C is \" + str(lin_clf.C))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "uniform_classifier = DummyClassifier(strategy='uniform')\n",
    "uniform_classifier.fit(train_binary_design, IMDB_train_y)\n",
    "print(\"The f1_measure on test set for Random classifier is :\" \n",
    "      + str(f1_score(IMDB_test_y,uniform_classifier.predict(test_binary_design), average = 'micro')))\n",
    "\n",
    "uniform_classifier.predict(test_binary_design)\n",
    "\n",
    "majority_classifier = DummyClassifier(strategy='most_frequent') \n",
    "majority_classifier.fit(train_binary_design, IMDB_train_y)\n",
    "\n",
    "print(\"The f1_measure on test set for majority-class classifier is :\" \n",
    "      + str(f1_score(IMDB_test_y, majority_classifier.predict(test_binary_design), average = 'micro')))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The f1_measure on training set for Gaussian naive bayes using frequency bag of words is :0.6252\n",
      "The f1_measure on validation set for Gaussian naive bayes using frequency bag of words is :0.6021\n",
      "The f1_measure on test set for Gaussian naive bayes using frequency bag of words is :0.58588\n",
      "The f1_measure on training set for classification tree using frequency bag of words is :1.0\n",
      "The f1_measure on validation set for classification tree using frequency bag of words is :0.6123\n",
      "The f1_measure on test set for classification tree using frequency bag of words is :0.6118\n",
      "Corresponding max_features, min_samples_leaf, max_depth are 1, 1, 1\n",
      "The f1_measure on training set for LinearSVC using frequency bag of words is :0.7667333333333334\n",
      "The f1_measure on validation set for LinearSVC using frequency bag of words is :0.7506\n",
      "The f1_measure on test set for LinearSVC using frequency bag of words is :0.7572\n",
      "The corresponding vlaue of C is 1e-90\n",
      "The f1_measure on test set for Random classifier is :0.49988\n",
      "The f1_measure on test set for majority-class classifier is :0.5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "########hyper parameter tuning######\n",
    "\n",
    "#train_frequency_design, train_binary_design = train_frequency_design.toarray(), train_binary_design.toarray()\n",
    "#valid_frequency_design, valid_binary_design = valid_frequency_design.toarray(), valid_binary_design.toarray() \n",
    "#test_frequency_design, test_binary_design = test_frequency_design.toarray(), test_binary_design.toarray()\n",
    "\n",
    "clf = GaussianNB()\n",
    "clf.fit(train_frequency_design.toarray(), IMDB_train_y)\n",
    "\n",
    "\n",
    "\n",
    "print(\"The f1_measure on training set for Gaussian naive bayes using frequency bag of words is :\" + \n",
    "      str(f1_score(y_true =IMDB_train_y, y_pred = clf.predict(train_frequency_design.toarray()), average = 'micro')))\n",
    "\n",
    "\n",
    "print(\"The f1_measure on validation set for Gaussian naive bayes using frequency bag of words is :\" + \n",
    "      str(f1_score(y_true =IMDB_valid_y, y_pred = clf.predict(valid_frequency_design.toarray()), average = 'micro')))\n",
    "\n",
    "\n",
    "\n",
    "print(\"The f1_measure on test set for Gaussian naive bayes using frequency bag of words is :\" + \n",
    "      str(f1_score(y_true =IMDB_test_y, y_pred = clf.predict(test_frequency_design.toarray()), average = 'micro')))\n",
    "\n",
    "\n",
    "\n",
    "####Decision tree max leaf, min sample max depth training\n",
    "\n",
    "\n",
    "\n",
    "decision_tree = tree.DecisionTreeClassifier()\n",
    "decision_tree.fit(train_frequency_design, IMDB_train_y)\n",
    "\n",
    "\n",
    "max_features = [i for i in range(1,20)]\n",
    "min_samples_leaf = [i for i in range(1,20)]\n",
    "max_depth = [i for i in range(1,20)]\n",
    "best_f1_2 = -10\n",
    "q = [] \n",
    "for i in max_features:\n",
    "    for j in min_samples_leaf:\n",
    "        for k in max_depth:\n",
    "            decision_tree.max_features = i\n",
    "            decision_tree.min_samples_leaf = j\n",
    "            decision_tree.max_depth = k\n",
    "            f1_measure = f1_score(IMDB_valid_y,decision_tree.predict(valid_frequency_design), average='micro')\n",
    "            if (best_f1_2 < f1_measure):\n",
    "                best_i = i\n",
    "                best_j = j\n",
    "                best_k = k \n",
    "                best_f1_2 = f1_measure\n",
    "decision_tree.max_features = best_i\n",
    "decision_tree.max_features = best_j\n",
    "decision_tree.max_features = best_k \n",
    "print(\"The f1_measure on training set for classification tree using frequency bag of words is :\" \n",
    "      + str(f1_score(y_true = IMDB_train_y, y_pred = decision_tree.predict(train_frequency_design), average = 'micro')))\n",
    "\n",
    "\n",
    "\n",
    "print(\"The f1_measure on validation set for classification tree using frequency bag of words is :\" \n",
    "      + str(f1_score(y_true = IMDB_valid_y, y_pred = decision_tree.predict(valid_frequency_design), average = 'micro')))\n",
    "\n",
    "print(\"The f1_measure on test set for classification tree using frequency bag of words is :\" \n",
    "      + str(f1_score(y_true = IMDB_test_y, y_pred = decision_tree.predict(test_frequency_design), average = 'micro')))\n",
    "\n",
    "print(\"Corresponding max_features, min_samples_leaf, max_depth are \" \n",
    "      + str(best_i) + \", \" + str(best_j)+ \", \" +str(best_k))\n",
    "\n",
    "\n",
    "####Decision tree max leaf, min sample max depth training \n",
    "\n",
    "lin_clf = LinearSVC()\n",
    "lin_clf.fit(train_frequency_design, IMDB_train_y)\n",
    "\n",
    "\n",
    "C = []\n",
    "for i in range(0,100):\n",
    "    C.append(math.pow(10,(i-90)))\n",
    "\n",
    "best_f1_3 = -10\n",
    "k=0\n",
    "for i in C:\n",
    "    lin_clf.C = i\n",
    "    f1_measure = f1_score(IMDB_valid_y,lin_clf.predict(valid_frequency_design), average='micro')\n",
    "    if (best_f1_3 < f1_measure):\n",
    "        k = i\n",
    "        best_f1_3 = f1_measure\n",
    "lin_clf.C = k    \n",
    "\n",
    "\n",
    "print(\"The f1_measure on training set for LinearSVC using frequency bag of words is :\" + \n",
    "      str(f1_score(IMDB_train_y, lin_clf.predict(train_frequency_design), average = 'micro')))\n",
    "\n",
    "print(\"The f1_measure on validation set for LinearSVC using frequency bag of words is :\" + \n",
    "      str(f1_score(IMDB_valid_y, lin_clf.predict(valid_frequency_design), average = 'micro')))\n",
    "\n",
    "print(\"The f1_measure on test set for LinearSVC using frequency bag of words is :\" + \n",
    "      str(f1_score(IMDB_test_y, lin_clf.predict(test_frequency_design), average = 'micro')))\n",
    "print(\"The corresponding vlaue of C is \" + str(lin_clf.C))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "uniform_classifier = DummyClassifier(strategy='uniform')\n",
    "uniform_classifier.fit(train_frequency_design, IMDB_train_y)\n",
    "print(\"The f1_measure on test set for Random classifier is :\" + \n",
    "      str(f1_score(IMDB_test_y,uniform_classifier.predict(test_frequency_design), average = 'micro')))\n",
    "\n",
    "\n",
    "majority_classifier = DummyClassifier(strategy='most_frequent') \n",
    "majority_classifier.fit(train_frequency_design, IMDB_train_y)\n",
    "\n",
    "print(\"The f1_measure on test set for majority-class classifier is :\" + \n",
    "      str(f1_score(IMDB_test_y, majority_classifier.predict(test_frequency_design), average = 'micro')))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
